{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ActualBest imagegenerator model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYqRZ5n8hkM-"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import imageio\n",
        "from torch import nn\n",
        "\n",
        "image_size=128\n",
        "label_dim = 1\n",
        "One_Hot_dim=75\n",
        "G_input_dim = 128\n",
        "G_output_dim = 3\n",
        "D_input_dim = 3\n",
        "D_output_dim = 1\n",
        "num_filters = [1024, 512, 256, 128, 64, 32]\n",
        "\n",
        "learning_rate = 0.0001\n",
        "betas = (0.5, 0.999)\n",
        "batch_size = 20\n",
        "num_epochs = 500\n",
        "\n",
        "# For logger\n",
        "def to_np(x):\n",
        "    return x.data.cpu().numpy()\n",
        "\n",
        "\n",
        "def to_var(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)\n",
        "\n",
        "\n",
        "# De-normalization\n",
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.l1=nn.Sequential(nn.Linear(One_Hot_dim,G_input_dim),nn.ReLU(),nn.Linear(G_input_dim,G_input_dim))\n",
        "    def forward(self,x):\n",
        "        reses=torch.zeros(batch_size,G_input_dim).cuda()\n",
        "        for i in range(5):\n",
        "            res=self.l1(x[:,i*One_Hot_dim:(i+1)*One_Hot_dim])\n",
        "            reses += res\n",
        "        return reses\n",
        "            \n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.l=nn.Linear(G_input_dim,G_input_dim)\n",
        "        self.main = nn.Sequential(\n",
        "            \n",
        "            nn.ConvTranspose2d(G_input_dim, 512, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, G_output_dim, 4, 2, 1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, attr):\n",
        "        return self.main(self.l(x).view(-1,G_input_dim,1,1))\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.feature_input = nn.Linear(G_input_dim, image_size * image_size)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(D_input_dim+1, 32, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, attr):\n",
        "        x=torch.cat([x,self.feature_input(attr).view(-1,1,image_size,image_size)],1)\n",
        "        return self.main(x).view(-1, 1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS133poU_jbR",
        "outputId": "bf5d1ed0-ae6b-42b1-f91f-e8a9c6e5c4b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNvnY-xKXCGR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "cc386cef-feab-479d-cd15-f1c60e97a312"
      },
      "source": [
        "import pickle\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "f=open('drive/MyDrive/iclevrdata.pkl','rb')\n",
        "#f=open('data (1).pkl','rb')\n",
        "alldata = pickle.load(f)\n",
        "\n",
        "lam=0.0015\n",
        "\n",
        "\n",
        "\n",
        "def one_hot_list(ii,l):\n",
        "  li=[]\n",
        "  for i in range(l):\n",
        "    li.append(0)\n",
        "  li[ii]=1\n",
        "  return li\n",
        "\n",
        "materialmap={'rubber':0,'metal':1}\n",
        "colormap={'red':0,'green':1,'blue':2,'cyan':3,'brown':4,'gray':5,'purple':6,'yellow':7}\n",
        "shapemap={'sphere':0, 'cube':1, 'cylinder':2}\n",
        "\n",
        "def datatovec(d):\n",
        "  complete=[]\n",
        "  #print(d)\n",
        "  #print(len(d))\n",
        "  for i in d:\n",
        "    complete += (one_hot_list((i['pixel_coords'][0])//15,32)+one_hot_list((i['pixel_coords'][1])//10,32)+one_hot_list(shapemap[i['shape']],3)+one_hot_list(colormap[i['color']],8))\n",
        "  complete += ([0]*(13*(5-len(d))))\n",
        "  #print(complete)\n",
        "  return complete\n",
        "\n",
        "def takeavg(li):\n",
        "  a=0\n",
        "  for i in li:\n",
        "    a+=i\n",
        "  return a/float(len(li))\n",
        "\n",
        "\"\"\"\n",
        "def boxonly(ds):\n",
        "  mask=torch.zeros(batch_size,G_output_dim,image_size,image_size).cuda()\n",
        "  for j in range(len(ds)):\n",
        "    for i in ds[j]:\n",
        "      #print(i)\n",
        "      mask[j,:,int(i['ymin']/5.0):int(i['ymax']/5.0),int(i['xmin']/7.5):int(i['xmax']/7.5)]=1\n",
        "  return mask\n",
        "\"\"\"\n",
        "    \n",
        "\n",
        "\n",
        "import copy\n",
        "\n",
        "G = Generator()\n",
        "D = Discriminator()\n",
        "E = Encoder()\n",
        "DE= Encoder()\n",
        "G.cuda()\n",
        "D.cuda()\n",
        "E.cuda()\n",
        "DE.cuda()\n",
        "G_optimizer = torch.optim.RMSprop(G.parameters(), lr=learning_rate)\n",
        "D_optimizer = torch.optim.RMSprop(D.parameters(), lr=learning_rate,weight_decay=0.02)\n",
        "E_optimizer = torch.optim.RMSprop(E.parameters(), lr=learning_rate)\n",
        "DE_optimizer = torch.optim.RMSprop(DE.parameters(), lr=learning_rate)\n",
        "\n",
        "G=torch.load('/content/drive/MyDrive/G_128_20.pt')\n",
        "E=torch.load('/content/drive/MyDrive/E_128_20.pt')\n",
        "G.cuda()\n",
        "E.cuda()\n",
        "G_optimizer = torch.optim.RMSprop(G.parameters(), lr=learning_rate)\n",
        "E_optimizer = torch.optim.RMSprop(E.parameters(), lr=learning_rate)\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "fill = torch.ones([batch_size, label_dim, image_size, image_size])\n",
        "train_data=[(datatovec(x[0]),cv2.resize(x[1],(image_size,image_size)),x[0]) for x in alldata['train']]\n",
        "valid_data=[(datatovec(x[0]),cv2.resize(x[1],(image_size,image_size)),x[0]) for x in alldata['val']]\n",
        "baseimg=copy.deepcopy(train_data[0][1])\n",
        "\n",
        "def toimg(li):\n",
        "  for i in range(3):\n",
        "    for j in range(image_size):\n",
        "      for k in range(image_size):\n",
        "        #print(i)\n",
        "        #print(j)\n",
        "        #print(k)\n",
        "        baseimg[j,k,i]=li[i][j][k]*255\n",
        "  return baseimg\n",
        "\n",
        "\"\"\"\n",
        "for epoch in range(20):\n",
        "  for i in range(len(train_data)//batch_size):\n",
        "    start=i*batch_size\n",
        "    end=(i+1)*batch_size\n",
        "    trains=train_data[start:end]\n",
        "    train_imgs=[x[1] for x in trains]\n",
        "    train_vecs=[x[0] for x in trains]\n",
        "    x_real=(torch.FloatTensor(train_imgs)/256).transpose(2,3).transpose(1,2).cuda()\n",
        "    gen_image=G(E(torch.FloatTensor(train_vecs).view(batch_size,-1).cuda()),start).squeeze()\n",
        "    G_loss2=torch.nn.MSELoss()(gen_image,x_real)\n",
        "    G.zero_grad()\n",
        "    E.zero_grad()\n",
        "    G_loss2.backward()\n",
        "    G_optimizer.step()\n",
        "    E_optimizer.step()\n",
        "    print(G_loss2)\n",
        "\n",
        "torch.save(G,'/content/drive/MyDrive/G_128_20.pt')\n",
        "torch.save(E,'/content/drive/MyDrive/E_128_20.pt')\n",
        "\"\"\"\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  random.shuffle(train_data)\n",
        "  if epoch%10==9:\n",
        "    G_optimizer.param_groups[0]['lr'] /= 2\n",
        "    D_optimizer.param_groups[0]['lr'] /= 2\n",
        "  GMSELoss=[]\n",
        "  GPMSELoss=[]\n",
        "  GGANLoss=[]\n",
        "  DLoss=[]\n",
        "  \n",
        "  drange = 2\n",
        "  if epoch == 0:\n",
        "    drange = 40\n",
        "    \n",
        "  for i in range(len(train_data)//batch_size):\n",
        "    start=i*batch_size\n",
        "    end=(i+1)*batch_size\n",
        "    trains=train_data[start:end]\n",
        "    train_imgs=[x[1] for x in trains]\n",
        "    train_vecs=[x[0] for x in trains]\n",
        "    y_real_ = Variable(torch.ones(batch_size).cuda())\n",
        "    y_fake_ = Variable(torch.zeros(batch_size).cuda())\n",
        "    c=Variable(torch.ones(batch_size).view(-1,1,1,1)).cuda()\n",
        "    x_real=(torch.FloatTensor(train_imgs)/256).transpose(2,3).transpose(1,2).cuda()\n",
        "    \n",
        "    dl=1\n",
        "    for iii in range(drange):\n",
        "      \n",
        "      \n",
        "\n",
        "      gen_vecs=E(torch.FloatTensor(train_vecs).view(batch_size,-1).cuda())\n",
        "      dgen_vecs=DE(torch.FloatTensor(train_vecs).view(batch_size,-1).cuda())\n",
        "      D_real=D(x_real,dgen_vecs).squeeze()\n",
        "      D_real_loss=criterion(D_real,y_real_)\n",
        "      #print('Real '+str(D_real_loss))\n",
        "\n",
        "\n",
        "      \n",
        "      gen_image=G(gen_vecs,c).squeeze()\n",
        "      D_fake=D(gen_image,dgen_vecs).squeeze()\n",
        "      D_fake_loss=criterion(D_fake,y_fake_)\n",
        "      #print('Fake '+str(D_fake_loss))\n",
        "\n",
        "      D_BCE_loss=D_real_loss+D_fake_loss\n",
        "      #D_loss=torch.mean(D_fake)-torch.mean(D_real)\n",
        "      DLoss.append(D_BCE_loss)\n",
        "      D.zero_grad()\n",
        "      DE.zero_grad()\n",
        "      D_BCE_loss.backward()\n",
        "      D_optimizer.step()\n",
        "      DE_optimizer.step()\n",
        "      dl=takeavg(DLoss)\n",
        "    \n",
        "\n",
        "    gen_vecs=E(torch.FloatTensor(train_vecs).view(batch_size,-1).cuda())\n",
        "    gen_image=G(gen_vecs,c).squeeze()\n",
        "    dgen_vecs=DE(torch.FloatTensor(train_vecs).view(batch_size,-1).cuda())\n",
        "    D_fake=D(gen_image,dgen_vecs).squeeze()\n",
        "    G_loss1=criterion(D_fake,y_real_)\n",
        "    GGANLoss.append(G_loss1)\n",
        "    #mask=boxonly([x[2] for x in trains])\n",
        "    G_loss2=torch.nn.MSELoss()(gen_image,x_real)\n",
        "    #G_loss3=torch.nn.MSELoss()(gen_image*mask,x_real*mask)\n",
        "    GMSELoss.append(G_loss2)\n",
        "    #GPMSELoss.append(G_loss3)\n",
        "    G_loss=lam*G_loss1+G_loss2\n",
        "\n",
        "    \n",
        "    G.zero_grad()\n",
        "    E.zero_grad()\n",
        "    G_loss.backward()\n",
        "    E_optimizer.step()\n",
        "    G_optimizer.step()\n",
        "\n",
        "    if i==0:\n",
        "        img=gen_image[0].tolist()\n",
        "        cv2_imshow(toimg(img))\n",
        "        #img=(gen_image[0]*mask[0]).tolist()\n",
        "        #cv2_imshow(toimg(img))\n",
        "        img=x_real[0].tolist()\n",
        "        cv2_imshow(toimg(img))\n",
        "        #img=(x_real[0]*mask[0]).tolist()\n",
        "        #cv2_imshow(toimg(img))\n",
        "\n",
        "  #print(DLoss)\n",
        "  print(\"Epoch \"+str(epoch)+\" GMSE: \"+str(takeavg(GMSELoss))+\" GGAN: \"+str(takeavg(GGANLoss))+\"\\n\")\n",
        "  GMSELoss=[]\n",
        "  DLoss=[]\n",
        "  GGANLoss=[]\n",
        "  with torch.no_grad():\n",
        "    for i in range(len(valid_data)//batch_size):\n",
        "      start=i*batch_size\n",
        "      end=(i+1)*batch_size\n",
        "      trains=valid_data[start:end]\n",
        "      train_imgs=[x[1] for x in trains]\n",
        "      train_vecs=[x[0] for x in trains]\n",
        "      y_real_ = Variable(torch.ones(batch_size).cuda())\n",
        "      y_fake_ = Variable(torch.zeros(batch_size).cuda())\n",
        "      c=Variable(torch.ones(batch_size).view(-1,1,1,1)).cuda()\n",
        "      x_real=(torch.FloatTensor(train_imgs)/256).transpose(2,3).transpose(1,2).cuda()\n",
        "\n",
        "      gen_vecs=E(torch.FloatTensor(train_vecs).view(batch_size,-1).cuda())\n",
        "      dgen_vecs=DE(torch.FloatTensor(train_vecs).view(batch_size,-1).cuda())\n",
        "      D_real=D(x_real,dgen_vecs).squeeze()\n",
        "      D_real_loss=criterion(D_real,y_real_)\n",
        "\n",
        "\n",
        "      gen_image=G(gen_vecs,c).squeeze()\n",
        "      \n",
        "      D_fake=D(gen_image,dgen_vecs).squeeze()\n",
        "      D_fake_loss=criterion(D_fake,y_fake_)\n",
        "\n",
        "      D_loss=D_real_loss+D_fake_loss\n",
        "      DLoss.append(D_loss)\n",
        "\n",
        "      G_loss1=criterion(D_fake,y_real_)\n",
        "      GGANLoss.append(G_loss1)\n",
        "      G_loss2=torch.nn.MSELoss()(gen_image,x_real)\n",
        "      #mask=boxonly([x[2] for x in trains])\n",
        "      #G_loss3=torch.nn.MSELoss()(gen_image*mask,x_real*mask)\n",
        "      GMSELoss.append(G_loss2)\n",
        "      #GPMSELoss.append(G_loss3)\n",
        "\n",
        "      if i==0:\n",
        "        img=gen_image[0].tolist()\n",
        "        cv2_imshow(toimg(img))\n",
        "        #img=(gen_image[0]*mask[0]).tolist()\n",
        "        #cv2_imshow(toimg(img))\n",
        "        img=x_real[0].tolist()\n",
        "        cv2_imshow(toimg(img))\n",
        "        #img=(x_real[0]*mask[0]).tolist()\n",
        "        #cv2_imshow(toimg(img))\n",
        "  print(\"Epoch \"+str(epoch)+\" valid loss: D_loss: \"+str(takeavg(DLoss))+\" GMSE: \"+str(takeavg(GMSELoss))+\" GGAN: \"+str(takeavg(GGANLoss))+\"\\n\")\n",
        "  if epoch%25 == 24:\n",
        "    torch.save(G,'/content/drive/MyDrive/G_gan_'+str(epoch)+'.pt')\n",
        "    torch.save(E,'/content/drive/MyDrive/E_gan_'+str(epoch)+'.pt')\n",
        "\n",
        "\n",
        "    \n",
        "  \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-72709ed51c02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/iclevrdata.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#f=open('data (1).pkl','rb')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0malldata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/iclevrdata.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9AXASrn3eDg"
      },
      "source": [
        "torch.save(G,'/content/drive/MyDrive/G_gan.pt')\r\n",
        "torch.save(E,'/content/drive/MyDrive/E_gan.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LnP6ollc5C3",
        "outputId": "a7018f90-4024-440f-e117-24f786b87cb8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec  4 21:04:38 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    30W /  70W |   2039MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}